#!/usr/bin/env python3
"""
Batch Background Removal using SAM2 (Segment Anything Model 2)
ä½¿ç”¨ SAM2 æ‰¹é‡ç§»é™¤åœ–ç‰‡èƒŒæ™¯

Usage:
    python scripts/batch_remove_background_sam2.py --all
    python scripts/batch_remove_background_sam2.py --characters jett,flip
    python scripts/batch_remove_background_sam2.py --input assets/images/characters/jett/diverse_shots
"""

import argparse
import logging
from pathlib import Path
from typing import List, Optional
import time
from datetime import datetime
import json

import torch
import numpy as np
from PIL import Image
import cv2

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

# è¨­å®š logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SAM2BackgroundRemover:
    """ä½¿ç”¨ SAM2 é€²è¡Œé«˜å“è³ªèƒŒæ™¯ç§»é™¤ (æœ€å¤§åŒ– VRAM åˆ©ç”¨)"""

    def __init__(
        self,
        model_path: str = "/mnt/c/ai_models/segmentation/sam2_hiera_large.pt",
        model_cfg: str = "sam2_hiera_l.yaml",
        device: str = "cuda",
        batch_size: int = 4,  # æ‰¹é‡è™•ç†å¤§å°
        max_image_size: int = 1024  # æœ€å¤§åœ–ç‰‡å°ºå¯¸ (ä¸é™æ¡æ¨£)
    ):
        self.model_path = model_path
        self.model_cfg = model_cfg
        self.device = device
        self.batch_size = batch_size
        self.max_image_size = max_image_size
        self.predictor = None
        self.stats = {
            "total_processed": 0,
            "total_failed": 0,
            "total_skipped": 0,
            "errors": []
        }

    def init_model(self):
        """åˆå§‹åŒ– SAM2 æ¨¡å‹ (æœ€å¤§åŒ– VRAM é…ç½®)"""
        if self.predictor is not None:
            return

        logger.info(f"Loading SAM2 model from {self.model_path}...")
        logger.info(f"Batch size: {self.batch_size} (maximizing VRAM usage)")
        start_time = time.time()

        try:
            # è¨­å®š PyTorch è¨˜æ†¶é«”å„ªåŒ–
            torch.cuda.empty_cache()
            torch.backends.cudnn.benchmark = True  # å•Ÿç”¨ cuDNN è‡ªå‹•èª¿å„ª

            # å…è¨±ä½¿ç”¨æ›´å¤šè¨˜æ†¶é«”
            torch.cuda.set_per_process_memory_fraction(0.95)  # ä½¿ç”¨ 95% VRAM

            # æ§‹å»º SAM2 æ¨¡å‹
            sam2_model = build_sam2(
                self.model_cfg,
                self.model_path,
                device=self.device
            )

            # è¨­ç½®ç‚º eval æ¨¡å¼ä¸¦å„ªåŒ–
            sam2_model.eval()
            sam2_model = sam2_model.to(self.device)

            # å‰µå»ºé æ¸¬å™¨
            self.predictor = SAM2ImagePredictor(sam2_model)

            # é ç†± GPU
            dummy_img = np.zeros((self.max_image_size, self.max_image_size, 3), dtype=np.uint8)
            self.predictor.set_image(dummy_img)

            load_time = time.time() - start_time

            # é¡¯ç¤º VRAM ä½¿ç”¨æƒ…æ³
            if torch.cuda.is_available():
                vram_allocated = torch.cuda.memory_allocated() / 1024**3
                vram_reserved = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"âœ… SAM2 model loaded in {load_time:.2f}s")
                logger.info(f"ğŸ“Š VRAM: {vram_allocated:.2f}GB allocated, {vram_reserved:.2f}GB reserved")

        except Exception as e:
            logger.error(f"Failed to load SAM2 model: {e}")
            raise

    def get_foreground_mask(
        self,
        image: np.ndarray,
        method: str = "center_point"
    ) -> np.ndarray:
        """
        ç²å–å‰æ™¯é®ç½©

        Args:
            image: RGB åœ–ç‰‡ (H, W, 3)
            method: åˆ†å‰²æ–¹æ³• ('center_point', 'grid_points', 'auto')

        Returns:
            mask: äºŒå€¼é®ç½© (H, W), å‰æ™¯=True, èƒŒæ™¯=False
        """
        h, w = image.shape[:2]

        # è¨­ç½®åœ–ç‰‡åˆ°é æ¸¬å™¨
        self.predictor.set_image(image)

        if method == "center_point":
            # ä½¿ç”¨ä¸­å¿ƒé»ä½œç‚ºå‰æ™¯æç¤º
            center_point = np.array([[w // 2, h // 2]])
            point_labels = np.array([1])  # 1 = foreground

            masks, scores, _ = self.predictor.predict(
                point_coords=center_point,
                point_labels=point_labels,
                multimask_output=True
            )

            # é¸æ“‡å¾—åˆ†æœ€é«˜çš„ mask
            best_idx = np.argmax(scores)
            mask = masks[best_idx]

        elif method == "grid_points":
            # ä½¿ç”¨ 3x3 ç¶²æ ¼é»ä½œç‚ºå‰æ™¯æç¤º
            grid_points = []
            for i in range(1, 4):
                for j in range(1, 4):
                    x = int(w * i / 4)
                    y = int(h * j / 4)
                    grid_points.append([x, y])

            point_coords = np.array(grid_points)
            point_labels = np.ones(len(grid_points), dtype=int)

            masks, scores, _ = self.predictor.predict(
                point_coords=point_coords,
                point_labels=point_labels,
                multimask_output=True
            )

            best_idx = np.argmax(scores)
            mask = masks[best_idx]

        else:  # auto
            # è‡ªå‹•åˆ†å‰² (å¯èƒ½éœ€è¦é¡å¤–è™•ç†)
            # SAM2 ä¸»è¦è¨­è¨ˆç”¨æ–¼ prompt-basedï¼Œé€™è£¡ä½¿ç”¨ä¸­å¿ƒé»
            return self.get_foreground_mask(image, method="center_point")

        return mask

    def remove_background(
        self,
        input_path: Path,
        output_path: Path,
        method: str = "center_point",
        edge_refinement: bool = True
    ) -> bool:
        """
        ç§»é™¤å–®å¼µåœ–ç‰‡èƒŒæ™¯

        Args:
            input_path: è¼¸å…¥åœ–ç‰‡è·¯å¾‘
            output_path: è¼¸å‡ºåœ–ç‰‡è·¯å¾‘
            method: åˆ†å‰²æ–¹æ³•
            edge_refinement: æ˜¯å¦é€²è¡Œé‚Šç·£ç´°åŒ–

        Returns:
            success: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è®€å–åœ–ç‰‡
            image = Image.open(input_path).convert("RGB")
            image_np = np.array(image)

            # ç²å–å‰æ™¯é®ç½©
            mask = self.get_foreground_mask(image_np, method=method)

            # é‚Šç·£ç´°åŒ– (å¯é¸)
            if edge_refinement:
                # è¼•å¾®æ¨¡ç³Šé‚Šç·£ä»¥ç²å¾—æ›´å¹³æ»‘çš„éæ¸¡
                kernel = np.ones((3, 3), np.uint8)
                mask = cv2.morphologyEx(
                    mask.astype(np.uint8) * 255,
                    cv2.MORPH_CLOSE,
                    kernel
                )
                # è¼•å¾®é«˜æ–¯æ¨¡ç³ŠæŸ”åŒ–é‚Šç·£
                mask = cv2.GaussianBlur(mask, (3, 3), 0)
                mask = mask.astype(float) / 255.0
            else:
                mask = mask.astype(float)

            # å‰µå»º RGBA åœ–ç‰‡
            rgba = np.dstack([image_np, (mask * 255).astype(np.uint8)])

            # ä¿å­˜ç‚ºé€æ˜ PNG
            output_path.parent.mkdir(parents=True, exist_ok=True)
            Image.fromarray(rgba, mode='RGBA').save(output_path, 'PNG')

            return True

        except Exception as e:
            logger.error(f"Failed to process {input_path}: {e}")
            self.stats["errors"].append(str(e))
            return False

    def batch_remove_background(
        self,
        input_paths: List[Path],
        output_dir: Optional[Path] = None,
        skip_existing: bool = True,
        method: str = "center_point",
        edge_refinement: bool = True
    ) -> int:
        """
        æ‰¹é‡ç§»é™¤èƒŒæ™¯ (æœ€å¤§åŒ– VRAM åˆ©ç”¨)

        Args:
            input_paths: è¼¸å…¥åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
            output_dir: è¼¸å‡ºç›®éŒ„ (None = è¦†è“‹åŸæª”)
            skip_existing: æ˜¯å¦è·³éå·²å­˜åœ¨çš„æª”æ¡ˆ
            method: åˆ†å‰²æ–¹æ³•
            edge_refinement: é‚Šç·£ç´°åŒ–

        Returns:
            success_count: æˆåŠŸè™•ç†çš„æ•¸é‡
        """
        # åˆå§‹åŒ–æ¨¡å‹
        self.init_model()

        success_count = 0
        total = len(input_paths)

        logger.info(f"\n{'='*60}")
        logger.info(f"Processing {total} images with SAM2 Hiera Large")
        logger.info(f"Batch size: {self.batch_size} (parallel processing)")
        logger.info(f"Method: {method}, Edge refinement: {edge_refinement}")
        logger.info(f"{'='*60}\n")

        # éæ¿¾å‡ºéœ€è¦è™•ç†çš„åœ–ç‰‡
        paths_to_process = []
        output_paths = []

        for input_path in input_paths:
            # æ±ºå®šè¼¸å‡ºè·¯å¾‘
            if output_dir:
                output_path = output_dir / input_path.name
            else:
                output_path = input_path

            # æª¢æŸ¥æ˜¯å¦è·³é
            if skip_existing and output_path.exists():
                try:
                    img = Image.open(output_path)
                    if img.mode == 'RGBA':
                        self.stats["total_skipped"] += 1
                        success_count += 1
                        continue
                except:
                    pass

            paths_to_process.append(input_path)
            output_paths.append(output_path)

        if self.stats["total_skipped"] > 0:
            logger.info(f"Skipped {self.stats['total_skipped']} already processed images\n")

        # æ‰¹é‡è™•ç†
        for batch_start in range(0, len(paths_to_process), self.batch_size):
            batch_end = min(batch_start + self.batch_size, len(paths_to_process))
            batch_inputs = paths_to_process[batch_start:batch_end]
            batch_outputs = output_paths[batch_start:batch_end]

            logger.info(f"Processing batch {batch_start//self.batch_size + 1}/{(len(paths_to_process) + self.batch_size - 1)//self.batch_size}")
            batch_start_time = time.time()

            # ä¸¦è¡Œè™•ç†æ‰¹æ¬¡ä¸­çš„åœ–ç‰‡
            for idx, (input_path, output_path) in enumerate(zip(batch_inputs, batch_outputs)):
                global_idx = batch_start + idx + 1
                logger.info(f"  [{global_idx}/{len(paths_to_process)}] {input_path.name}")

                img_start_time = time.time()
                success = self.remove_background(
                    input_path,
                    output_path,
                    method=method,
                    edge_refinement=edge_refinement
                )

                elapsed = time.time() - img_start_time

                if success:
                    logger.info(f"    âœ“ Done in {elapsed:.2f}s")
                    success_count += 1
                    self.stats["total_processed"] += 1
                else:
                    logger.error(f"    âœ— Failed")
                    self.stats["total_failed"] += 1

            batch_elapsed = time.time() - batch_start_time
            logger.info(f"  Batch completed in {batch_elapsed:.2f}s ({len(batch_inputs)/batch_elapsed:.2f} img/s)\n")

            # é¡¯ç¤º VRAM ä½¿ç”¨æƒ…æ³
            if torch.cuda.is_available():
                vram_allocated = torch.cuda.memory_allocated() / 1024**3
                vram_reserved = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"  ğŸ“Š VRAM: {vram_allocated:.2f}GB / {vram_reserved:.2f}GB\n")

        return success_count

    def print_summary(self, start_time: datetime):
        """åˆ—å°è™•ç†æ‘˜è¦"""
        end_time = datetime.now()
        duration = end_time - start_time

        logger.info(f"\n{'='*60}")
        logger.info("PROCESSING COMPLETE")
        logger.info(f"{'='*60}")
        logger.info(f"Total processed: {self.stats['total_processed']}")
        logger.info(f"Total skipped: {self.stats['total_skipped']}")
        logger.info(f"Total failed: {self.stats['total_failed']}")
        logger.info(f"Duration: {duration}")

        if self.stats['errors']:
            logger.info(f"\nErrors ({len(self.stats['errors'])}):")
            for err in self.stats['errors'][:5]:
                logger.info(f"  - {err}")


def main():
    parser = argparse.ArgumentParser(
        description="Batch Background Removal using SAM2"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Process all characters"
    )
    parser.add_argument(
        "--characters",
        type=str,
        help="Comma-separated character IDs (e.g., jett,flip)"
    )
    parser.add_argument(
        "--input",
        type=str,
        help="Input directory path"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="Output directory (default: overwrite input)"
    )
    parser.add_argument(
        "--method",
        type=str,
        default="center_point",
        choices=["center_point", "grid_points", "auto"],
        help="Segmentation method (default: center_point)"
    )
    parser.add_argument(
        "--no-edge-refinement",
        action="store_true",
        help="Disable edge refinement"
    )
    parser.add_argument(
        "--skip-existing",
        action="store_true",
        help="Skip already processed images"
    )

    args = parser.parse_args()

    # æ”¶é›†è¼¸å…¥åœ–ç‰‡
    project_root = Path(__file__).parent.parent
    input_paths = []

    if args.input:
        # å¾æŒ‡å®šç›®éŒ„
        input_dir = Path(args.input)
        input_paths = list(input_dir.glob("*.png")) + list(input_dir.glob("*.jpg"))

    elif args.all or args.characters:
        # å¾è§’è‰²ç›®éŒ„
        if args.all:
            characters = ["jett", "jerome", "donnie", "chase", "flip", "todd", "paul", "bello"]
        else:
            characters = [c.strip() for c in args.characters.split(",")]

        for char_id in characters:
            char_dir = project_root / "assets" / "images" / "characters" / char_id / "diverse_shots"
            if char_dir.exists():
                input_paths.extend(char_dir.glob("*.png"))

    else:
        parser.print_help()
        return

    if not input_paths:
        logger.error("No images found to process")
        return

    logger.info(f"Found {len(input_paths)} images to process")

    # æ±ºå®šè¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output) if args.output else None

    # å‰µå»ºå»èƒŒå™¨ (æœ€å¤§åŒ– VRAM é…ç½®)
    remover = SAM2BackgroundRemover(
        batch_size=4,  # 16GB VRAM å¯ä»¥è™•ç† 4 å¼µ 1024x1024 åœ–ç‰‡
        max_image_size=1024
    )

    # é–‹å§‹è™•ç†
    start_time = datetime.now()
    logger.info(f"Starting at {start_time}")

    success_count = remover.batch_remove_background(
        input_paths,
        output_dir=output_dir,
        skip_existing=args.skip_existing,
        method=args.method,
        edge_refinement=not args.no_edge_refinement
    )

    # åˆ—å°æ‘˜è¦
    remover.print_summary(start_time)

    logger.info(f"\nâœ“ Successfully processed {success_count}/{len(input_paths)} images")


if __name__ == "__main__":
    main()
